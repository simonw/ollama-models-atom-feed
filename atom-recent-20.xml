<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Ollama models</title>
  <id>https://ollama.com/search?o=newest</id>
  <author>
    <name>Model Library</name>
  </author>
  <link href="https://ollama.com/search?o=newest" rel="self"/>
  <updated>2025-09-14T06:35:43.324435+00:00</updated>
  <entry>
    <title>embeddinggemma</title>
    <id>https://ollama.com/library/embeddinggemma</id>
    <link href="https://ollama.com/library/embeddinggemma"/>
    <summary>EmbeddingGemma is a 300M parameter embedding model from Google.</summary>
    <updated>2025-09-09T00:17:00+00:00</updated>
    <category term="300m"/>
    <category term="embedding"/>
    <content type="html">&lt;p&gt;EmbeddingGemma is a 300M parameter embedding model from Google.&lt;/p&gt;&lt;p&gt;Pulls: 20.1K&lt;/p&gt;&lt;p&gt;Tags: 5&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>deepseek-v3.1</title>
    <id>https://ollama.com/library/deepseek-v3.1</id>
    <link href="https://ollama.com/library/deepseek-v3.1"/>
    <summary>DeepSeek-V3.1 is a hybrid model that supports both thinking mode and non-thinking mode.</summary>
    <updated>2025-08-31T20:20:00+00:00</updated>
    <category term="671b"/>
    <category term="tools"/>
    <category term="thinking"/>
    <content type="html">&lt;p&gt;DeepSeek-V3.1 is a hybrid model that supports both thinking mode and non-thinking mode.&lt;/p&gt;&lt;p&gt;Pulls: 43.9K&lt;/p&gt;&lt;p&gt;Tags: 4&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>qwen3-coder</title>
    <id>https://ollama.com/library/qwen3-coder</id>
    <link href="https://ollama.com/library/qwen3-coder"/>
    <summary>Alibaba's performant long context models for agentic and coding tasks.</summary>
    <updated>2025-08-17T01:42:00+00:00</updated>
    <category term="30b"/>
    <category term="480b"/>
    <content type="html">&lt;p&gt;Alibaba's performant long context models for agentic and coding tasks.&lt;/p&gt;&lt;p&gt;Pulls: 359.9K&lt;/p&gt;&lt;p&gt;Tags: 9&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>gemma3</title>
    <id>https://ollama.com/library/gemma3</id>
    <link href="https://ollama.com/library/gemma3"/>
    <summary>The current, most capable model that runs on a single GPU.</summary>
    <updated>2025-08-15T08:15:00+00:00</updated>
    <category term="270m"/>
    <category term="1b"/>
    <category term="4b"/>
    <category term="12b"/>
    <category term="27b"/>
    <category term="vision"/>
    <content type="html">&lt;p&gt;The current, most capable model that runs on a single GPU.&lt;/p&gt;&lt;p&gt;Pulls: 16M&lt;/p&gt;&lt;p&gt;Tags: 26&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>gpt-oss</title>
    <id>https://ollama.com/library/gpt-oss</id>
    <link href="https://ollama.com/library/gpt-oss"/>
    <summary>OpenAI’s open-weight models designed for powerful reasoning, agentic tasks, and versatile developer use cases.</summary>
    <updated>2025-08-11T22:43:00+00:00</updated>
    <category term="20b"/>
    <category term="120b"/>
    <category term="tools"/>
    <category term="thinking"/>
    <content type="html">&lt;p&gt;OpenAI’s open-weight models designed for powerful reasoning, agentic tasks, and versatile developer use cases.&lt;/p&gt;&lt;p&gt;Pulls: 2.2M&lt;/p&gt;&lt;p&gt;Tags: 3&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>qwen3</title>
    <id>https://ollama.com/library/qwen3</id>
    <link href="https://ollama.com/library/qwen3"/>
    <summary>Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.</summary>
    <updated>2025-08-06T21:43:00+00:00</updated>
    <category term="0.6b"/>
    <category term="1.7b"/>
    <category term="4b"/>
    <category term="8b"/>
    <category term="14b"/>
    <category term="30b"/>
    <category term="32b"/>
    <category term="235b"/>
    <category term="tools"/>
    <category term="thinking"/>
    <content type="html">&lt;p&gt;Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.&lt;/p&gt;&lt;p&gt;Pulls: 8.1M&lt;/p&gt;&lt;p&gt;Tags: 56&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>mistral-nemo</title>
    <id>https://ollama.com/library/mistral-nemo</id>
    <link href="https://ollama.com/library/mistral-nemo"/>
    <summary>A state-of-the-art 12B model with 128k context length, built by Mistral AI in collaboration with NVIDIA.</summary>
    <updated>2025-07-23T18:43:00+00:00</updated>
    <category term="12b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;A state-of-the-art 12B model with 128k context length, built by Mistral AI in collaboration with NVIDIA.&lt;/p&gt;&lt;p&gt;Pulls: 2.6M&lt;/p&gt;&lt;p&gt;Tags: 17&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>mistral</title>
    <id>https://ollama.com/library/mistral</id>
    <link href="https://ollama.com/library/mistral"/>
    <summary>The 7B model released by Mistral AI, updated to version 0.3.</summary>
    <updated>2025-07-13T00:56:00+00:00</updated>
    <category term="7b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;The 7B model released by Mistral AI, updated to version 0.3.&lt;/p&gt;&lt;p&gt;Pulls: 19.1M&lt;/p&gt;&lt;p&gt;Tags: 84&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>devstral</title>
    <id>https://ollama.com/library/devstral</id>
    <link href="https://ollama.com/library/devstral"/>
    <summary>Devstral: the best open source model for coding agents</summary>
    <updated>2025-07-04T18:29:00+00:00</updated>
    <category term="24b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;Devstral: the best open source model for coding agents&lt;/p&gt;&lt;p&gt;Pulls: 341.9K&lt;/p&gt;&lt;p&gt;Tags: 5&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>deepseek-r1</title>
    <id>https://ollama.com/library/deepseek-r1</id>
    <link href="https://ollama.com/library/deepseek-r1"/>
    <summary>DeepSeek-R1 is a family of open reasoning models with performance approaching that of leading models, such as O3 and Gemini 2.5 Pro.</summary>
    <updated>2025-07-02T06:09:00+00:00</updated>
    <category term="1.5b"/>
    <category term="7b"/>
    <category term="8b"/>
    <category term="14b"/>
    <category term="32b"/>
    <category term="70b"/>
    <category term="671b"/>
    <category term="tools"/>
    <category term="thinking"/>
    <content type="html">&lt;p&gt;DeepSeek-R1 is a family of open reasoning models with performance approaching that of leading models, such as O3 and Gemini 2.5 Pro.&lt;/p&gt;&lt;p&gt;Pulls: 61.7M&lt;/p&gt;&lt;p&gt;Tags: 35&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>gemma3n</title>
    <id>https://ollama.com/library/gemma3n</id>
    <link href="https://ollama.com/library/gemma3n"/>
    <summary>Gemma 3n models are designed for efficient execution on everyday devices such as laptops, tablets or phones.</summary>
    <updated>2025-06-27T05:02:00+00:00</updated>
    <category term="e2b"/>
    <category term="e4b"/>
    <content type="html">&lt;p&gt;Gemma 3n models are designed for efficient execution on everyday devices such as laptops, tablets or phones.&lt;/p&gt;&lt;p&gt;Pulls: 465.8K&lt;/p&gt;&lt;p&gt;Tags: 9&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>mistral-small3.2</title>
    <id>https://ollama.com/library/mistral-small3.2</id>
    <link href="https://ollama.com/library/mistral-small3.2"/>
    <summary>An update to Mistral Small that improves on function calling, instruction following, and less repetition errors.</summary>
    <updated>2025-06-20T22:59:00+00:00</updated>
    <category term="24b"/>
    <category term="vision"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;An update to Mistral Small that improves on function calling, instruction following, and less repetition errors.&lt;/p&gt;&lt;p&gt;Pulls: 348.5K&lt;/p&gt;&lt;p&gt;Tags: 5&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>magistral</title>
    <id>https://ollama.com/library/magistral</id>
    <link href="https://ollama.com/library/magistral"/>
    <summary>Magistral is a small, efficient reasoning model with 24B parameters.</summary>
    <updated>2025-06-16T20:46:00+00:00</updated>
    <category term="24b"/>
    <category term="tools"/>
    <category term="thinking"/>
    <content type="html">&lt;p&gt;Magistral is a small, efficient reasoning model with 24B parameters.&lt;/p&gt;&lt;p&gt;Pulls: 363.6K&lt;/p&gt;&lt;p&gt;Tags: 5&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>llama4</title>
    <id>https://ollama.com/library/llama4</id>
    <link href="https://ollama.com/library/llama4"/>
    <summary>Meta's latest collection of multimodal models.</summary>
    <updated>2025-06-16T20:45:00+00:00</updated>
    <category term="16x17b"/>
    <category term="128x17b"/>
    <category term="vision"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;Meta's latest collection of multimodal models.&lt;/p&gt;&lt;p&gt;Pulls: 668.2K&lt;/p&gt;&lt;p&gt;Tags: 11&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>qwen2.5-coder</title>
    <id>https://ollama.com/library/qwen2.5-coder</id>
    <link href="https://ollama.com/library/qwen2.5-coder"/>
    <summary>The latest series of Code-Specific Qwen models, with significant improvements in code generation, code reasoning, and code fixing.</summary>
    <updated>2025-05-28T01:19:00+00:00</updated>
    <category term="0.5b"/>
    <category term="1.5b"/>
    <category term="3b"/>
    <category term="7b"/>
    <category term="14b"/>
    <category term="32b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;The latest series of Code-Specific Qwen models, with significant improvements in code generation, code reasoning, and code fixing.&lt;/p&gt;&lt;p&gt;Pulls: 7M&lt;/p&gt;&lt;p&gt;Tags: 199&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>qwen2.5vl</title>
    <id>https://ollama.com/library/qwen2.5vl</id>
    <link href="https://ollama.com/library/qwen2.5vl"/>
    <summary>Flagship vision-language model of Qwen and also a significant leap from the previous Qwen2-VL.</summary>
    <updated>2025-05-22T21:01:00+00:00</updated>
    <category term="3b"/>
    <category term="7b"/>
    <category term="32b"/>
    <category term="72b"/>
    <category term="vision"/>
    <content type="html">&lt;p&gt;Flagship vision-language model of Qwen and also a significant leap from the previous Qwen2-VL.&lt;/p&gt;&lt;p&gt;Pulls: 577.6K&lt;/p&gt;&lt;p&gt;Tags: 17&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>llama3.2-vision</title>
    <id>https://ollama.com/library/llama3.2-vision</id>
    <link href="https://ollama.com/library/llama3.2-vision"/>
    <summary>Llama 3.2 Vision is a collection of instruction-tuned image reasoning generative models in 11B and 90B sizes.</summary>
    <updated>2025-05-22T19:15:00+00:00</updated>
    <category term="11b"/>
    <category term="90b"/>
    <category term="vision"/>
    <content type="html">&lt;p&gt;Llama 3.2 Vision is a collection of instruction-tuned image reasoning generative models in 11B and 90B sizes.&lt;/p&gt;&lt;p&gt;Pulls: 2.4M&lt;/p&gt;&lt;p&gt;Tags: 9&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>phi4-reasoning</title>
    <id>https://ollama.com/library/phi4-reasoning</id>
    <link href="https://ollama.com/library/phi4-reasoning"/>
    <summary>Phi 4 reasoning and reasoning plus are 14-billion parameter open-weight reasoning models that rival much larger models on complex reasoning tasks.</summary>
    <updated>2025-05-01T05:32:00+00:00</updated>
    <category term="14b"/>
    <content type="html">&lt;p&gt;Phi 4 reasoning and reasoning plus are 14-billion parameter open-weight reasoning models that rival much larger models on complex reasoning tasks.&lt;/p&gt;&lt;p&gt;Pulls: 422.9K&lt;/p&gt;&lt;p&gt;Tags: 9&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>phi4-mini-reasoning</title>
    <id>https://ollama.com/library/phi4-mini-reasoning</id>
    <link href="https://ollama.com/library/phi4-mini-reasoning"/>
    <summary>Phi 4 mini reasoning is a lightweight open model that balances efficiency with advanced reasoning ability.</summary>
    <updated>2025-05-01T03:53:00+00:00</updated>
    <category term="3.8b"/>
    <content type="html">&lt;p&gt;Phi 4 mini reasoning is a lightweight open model that balances efficiency with advanced reasoning ability.&lt;/p&gt;&lt;p&gt;Pulls: 54.5K&lt;/p&gt;&lt;p&gt;Tags: 5&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>granite3.3</title>
    <id>https://ollama.com/library/granite3.3</id>
    <link href="https://ollama.com/library/granite3.3"/>
    <summary>IBM Granite 2B and 8B models are 128K context length language models that have been fine-tuned for improved reasoning and instruction-following capabilities.</summary>
    <updated>2025-04-16T14:49:00+00:00</updated>
    <category term="2b"/>
    <category term="8b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;IBM Granite 2B and 8B models are 128K context length language models that have been fine-tuned for improved reasoning and instruction-following capabilities.&lt;/p&gt;&lt;p&gt;Pulls: 458.6K&lt;/p&gt;&lt;p&gt;Tags: 3&lt;/p&gt;</content>
  </entry>
</feed>
