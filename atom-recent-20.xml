<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Ollama models</title>
  <id>https://ollama.com/search?o=newest</id>
  <author>
    <name>Model Library</name>
  </author>
  <link href="https://ollama.com/search?o=newest" rel="self"/>
  <updated>2025-05-03T06:35:33.712872+00:00</updated>
  <entry>
    <title>llama4</title>
    <id>https://ollama.com/library/llama4</id>
    <link href="https://ollama.com/library/llama4"/>
    <summary>Meta's latest collection of multimodal models.</summary>
    <updated>2025-05-01T19:28:00+00:00</updated>
    <category term="vision"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;Meta's latest collection of multimodal models.&lt;/p&gt;&lt;p&gt;Pulls: 5,121&lt;/p&gt;&lt;p&gt;Tags: 9&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>phi4-reasoning</title>
    <id>https://ollama.com/library/phi4-reasoning</id>
    <link href="https://ollama.com/library/phi4-reasoning"/>
    <summary>Phi 4 reasoning and reasoning plus are 14-billion parameter open-weight reasoning models that rival much larger models on complex reasoning tasks.</summary>
    <updated>2025-05-01T05:32:00+00:00</updated>
    <category term="14b"/>
    <content type="html">&lt;p&gt;Phi 4 reasoning and reasoning plus are 14-billion parameter open-weight reasoning models that rival much larger models on complex reasoning tasks.&lt;/p&gt;&lt;p&gt;Pulls: 8,058&lt;/p&gt;&lt;p&gt;Tags: 9&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>phi4-mini-reasoning</title>
    <id>https://ollama.com/library/phi4-mini-reasoning</id>
    <link href="https://ollama.com/library/phi4-mini-reasoning"/>
    <summary>Phi 4 mini reasoning is a lightweight open model that balances efficiency with advanced reasoning ability.</summary>
    <updated>2025-05-01T03:53:00+00:00</updated>
    <category term="3.8b"/>
    <content type="html">&lt;p&gt;Phi 4 mini reasoning is a lightweight open model that balances efficiency with advanced reasoning ability.&lt;/p&gt;&lt;p&gt;Pulls: 3,523&lt;/p&gt;&lt;p&gt;Tags: 5&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>qwen3</title>
    <id>https://ollama.com/library/qwen3</id>
    <link href="https://ollama.com/library/qwen3"/>
    <summary>Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.</summary>
    <updated>2025-04-28T21:50:00+00:00</updated>
    <category term="0.6b"/>
    <category term="1.7b"/>
    <category term="4b"/>
    <category term="8b"/>
    <category term="14b"/>
    <category term="30b"/>
    <category term="32b"/>
    <category term="235b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.&lt;/p&gt;&lt;p&gt;Pulls: 636.3K&lt;/p&gt;&lt;p&gt;Tags: 33&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>gemma3</title>
    <id>https://ollama.com/library/gemma3</id>
    <link href="https://ollama.com/library/gemma3"/>
    <summary>The current, most capable model that runs on a single GPU.</summary>
    <updated>2025-04-18T02:08:00+00:00</updated>
    <category term="1b"/>
    <category term="4b"/>
    <category term="12b"/>
    <category term="27b"/>
    <category term="vision"/>
    <content type="html">&lt;p&gt;The current, most capable model that runs on a single GPU.&lt;/p&gt;&lt;p&gt;Pulls: 4.1M&lt;/p&gt;&lt;p&gt;Tags: 21&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>granite3.3</title>
    <id>https://ollama.com/library/granite3.3</id>
    <link href="https://ollama.com/library/granite3.3"/>
    <summary>IBM Granite 2B and 8B models are 128K context length language models that have been fine-tuned for improved reasoning and instruction-following capabilities.</summary>
    <updated>2025-04-16T14:49:00+00:00</updated>
    <category term="2b"/>
    <category term="8b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;IBM Granite 2B and 8B models are 128K context length language models that have been fine-tuned for improved reasoning and instruction-following capabilities.&lt;/p&gt;&lt;p&gt;Pulls: 28.6K&lt;/p&gt;&lt;p&gt;Tags: 3&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>deepcoder</title>
    <id>https://ollama.com/library/deepcoder</id>
    <link href="https://ollama.com/library/deepcoder"/>
    <summary>DeepCoder is a fully open-Source 14B coder model at O3-mini level, with a 1.5B version also available.</summary>
    <updated>2025-04-08T22:53:00+00:00</updated>
    <category term="1.5b"/>
    <category term="14b"/>
    <content type="html">&lt;p&gt;DeepCoder is a fully open-Source 14B coder model at O3-mini level, with a 1.5B version also available.&lt;/p&gt;&lt;p&gt;Pulls: 67.2K&lt;/p&gt;&lt;p&gt;Tags: 9&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>cogito</title>
    <id>https://ollama.com/library/cogito</id>
    <link href="https://ollama.com/library/cogito"/>
    <summary>Cogito v1 Preview is a family of hybrid reasoning models by Deep Cogito that outperform the best available open models of the same size, including counterparts from LLaMA, DeepSeek, and Qwen across most standard benchmarks.</summary>
    <updated>2025-04-08T17:38:00+00:00</updated>
    <category term="3b"/>
    <category term="8b"/>
    <category term="14b"/>
    <category term="32b"/>
    <category term="70b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;Cogito v1 Preview is a family of hybrid reasoning models by Deep Cogito that outperform the best available open models of the same size, including counterparts from LLaMA, DeepSeek, and Qwen across most standard benchmarks.&lt;/p&gt;&lt;p&gt;Pulls: 57.1K&lt;/p&gt;&lt;p&gt;Tags: 20&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>mistral-small3.1</title>
    <id>https://ollama.com/library/mistral-small3.1</id>
    <link href="https://ollama.com/library/mistral-small3.1"/>
    <summary>Building upon Mistral Small 3, Mistral Small 3.1 (2503) adds state-of-the-art vision understanding and enhances long context capabilities up to 128k tokens without compromising text performance.</summary>
    <updated>2025-04-07T16:59:00+00:00</updated>
    <category term="24b"/>
    <category term="vision"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;Building upon Mistral Small 3, Mistral Small 3.1 (2503) adds state-of-the-art vision understanding and enhances long context capabilities up to 128k tokens without compromising text performance.&lt;/p&gt;&lt;p&gt;Pulls: 69.9K&lt;/p&gt;&lt;p&gt;Tags: 5&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>openthinker</title>
    <id>https://ollama.com/library/openthinker</id>
    <link href="https://ollama.com/library/openthinker"/>
    <summary>A fully open-source family of reasoning models built using a dataset derived by distilling DeepSeek-R1.</summary>
    <updated>2025-04-04T21:52:00+00:00</updated>
    <category term="7b"/>
    <category term="32b"/>
    <content type="html">&lt;p&gt;A fully open-source family of reasoning models built using a dataset derived by distilling DeepSeek-R1.&lt;/p&gt;&lt;p&gt;Pulls: 523.3K&lt;/p&gt;&lt;p&gt;Tags: 15&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>exaone-deep</title>
    <id>https://ollama.com/library/exaone-deep</id>
    <link href="https://ollama.com/library/exaone-deep"/>
    <summary>EXAONE Deep exhibits superior capabilities in various reasoning tasks including math and coding benchmarks, ranging from 2.4B to 32B parameters developed and released by LG AI Research.</summary>
    <updated>2025-03-19T17:04:00+00:00</updated>
    <category term="2.4b"/>
    <category term="7.8b"/>
    <category term="32b"/>
    <content type="html">&lt;p&gt;EXAONE Deep exhibits superior capabilities in various reasoning tasks including math and coding benchmarks, ranging from 2.4B to 32B parameters developed and released by LG AI Research.&lt;/p&gt;&lt;p&gt;Pulls: 33.8K&lt;/p&gt;&lt;p&gt;Tags: 13&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>qwq</title>
    <id>https://ollama.com/library/qwq</id>
    <link href="https://ollama.com/library/qwq"/>
    <summary>QwQ is the reasoning model of the Qwen series.</summary>
    <updated>2025-03-13T18:55:00+00:00</updated>
    <category term="32b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;QwQ is the reasoning model of the Qwen series.&lt;/p&gt;&lt;p&gt;Pulls: 1.4M&lt;/p&gt;&lt;p&gt;Tags: 8&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>command-a</title>
    <id>https://ollama.com/library/command-a</id>
    <link href="https://ollama.com/library/command-a"/>
    <summary>111 billion parameter model optimized for demanding enterprises that require fast, secure, and high-quality AI</summary>
    <updated>2025-03-13T12:39:00+00:00</updated>
    <category term="111b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;111 billion parameter model optimized for demanding enterprises that require fast, secure, and high-quality AI&lt;/p&gt;&lt;p&gt;Pulls: 9,934&lt;/p&gt;&lt;p&gt;Tags: 5&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>command-r7b-arabic</title>
    <id>https://ollama.com/library/command-r7b-arabic</id>
    <link href="https://ollama.com/library/command-r7b-arabic"/>
    <summary>A new state-of-the-art version of the lightweight Command R7B model that excels in advanced Arabic language capabilities for enterprises in the Middle East and Northern Africa.</summary>
    <updated>2025-02-28T21:28:00+00:00</updated>
    <category term="7b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;A new state-of-the-art version of the lightweight Command R7B model that excels in advanced Arabic language capabilities for enterprises in the Middle East and Northern Africa.&lt;/p&gt;&lt;p&gt;Pulls: 5,514&lt;/p&gt;&lt;p&gt;Tags: 5&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>phi4-mini</title>
    <id>https://ollama.com/library/phi4-mini</id>
    <link href="https://ollama.com/library/phi4-mini"/>
    <summary>Phi-4-mini brings significant enhancements in multilingual support, reasoning, and mathematics, and now, the long-awaited function calling feature is finally supported.</summary>
    <updated>2025-02-28T20:02:00+00:00</updated>
    <category term="3.8b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;Phi-4-mini brings significant enhancements in multilingual support, reasoning, and mathematics, and now, the long-awaited function calling feature is finally supported.&lt;/p&gt;&lt;p&gt;Pulls: 123.3K&lt;/p&gt;&lt;p&gt;Tags: 5&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>granite3.2-vision</title>
    <id>https://ollama.com/library/granite3.2-vision</id>
    <link href="https://ollama.com/library/granite3.2-vision"/>
    <summary>A compact and efficient vision-language model, specifically designed for visual document understanding, enabling automated content extraction from tables, charts, infographics, plots, diagrams, and more.</summary>
    <updated>2025-02-27T19:26:00+00:00</updated>
    <category term="2b"/>
    <category term="vision"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;A compact and efficient vision-language model, specifically designed for visual document understanding, enabling automated content extraction from tables, charts, infographics, plots, diagrams, and more.&lt;/p&gt;&lt;p&gt;Pulls: 58.9K&lt;/p&gt;&lt;p&gt;Tags: 5&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>granite3.2</title>
    <id>https://ollama.com/library/granite3.2</id>
    <link href="https://ollama.com/library/granite3.2"/>
    <summary>Granite-3.2 is a family of long-context AI models from IBM Granite fine-tuned for thinking capabilities.</summary>
    <updated>2025-02-26T05:48:00+00:00</updated>
    <category term="2b"/>
    <category term="8b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;Granite-3.2 is a family of long-context AI models from IBM Granite fine-tuned for thinking capabilities.&lt;/p&gt;&lt;p&gt;Pulls: 92K&lt;/p&gt;&lt;p&gt;Tags: 9&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>r1-1776</title>
    <id>https://ollama.com/library/r1-1776</id>
    <link href="https://ollama.com/library/r1-1776"/>
    <summary>A version of the DeepSeek-R1 model that has been post trained to provide unbiased, accurate, and factual information by Perplexity.</summary>
    <updated>2025-02-21T15:28:00+00:00</updated>
    <category term="70b"/>
    <category term="671b"/>
    <content type="html">&lt;p&gt;A version of the DeepSeek-R1 model that has been post trained to provide unbiased, accurate, and factual information by Perplexity.&lt;/p&gt;&lt;p&gt;Pulls: 27.9K&lt;/p&gt;&lt;p&gt;Tags: 9&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>deepscaler</title>
    <id>https://ollama.com/library/deepscaler</id>
    <link href="https://ollama.com/library/deepscaler"/>
    <summary>A fine-tuned version of Deepseek-R1-Distilled-Qwen-1.5B that surpasses the performance of OpenAI’s o1-preview with just 1.5B parameters on popular math evaluations.</summary>
    <updated>2025-02-12T01:53:00+00:00</updated>
    <category term="1.5b"/>
    <content type="html">&lt;p&gt;A fine-tuned version of Deepseek-R1-Distilled-Qwen-1.5B that surpasses the performance of OpenAI’s o1-preview with just 1.5B parameters on popular math evaluations.&lt;/p&gt;&lt;p&gt;Pulls: 78.1K&lt;/p&gt;&lt;p&gt;Tags: 5&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>deepseek-r1</title>
    <id>https://ollama.com/library/deepseek-r1</id>
    <link href="https://ollama.com/library/deepseek-r1"/>
    <summary>DeepSeek's first-generation of reasoning models with comparable performance to OpenAI-o1, including six dense models distilled from DeepSeek-R1 based on Llama and Qwen.</summary>
    <updated>2025-02-07T01:40:00+00:00</updated>
    <category term="1.5b"/>
    <category term="7b"/>
    <category term="8b"/>
    <category term="14b"/>
    <category term="32b"/>
    <category term="70b"/>
    <category term="671b"/>
    <content type="html">&lt;p&gt;DeepSeek's first-generation of reasoning models with comparable performance to OpenAI-o1, including six dense models distilled from DeepSeek-R1 based on Llama and Qwen.&lt;/p&gt;&lt;p&gt;Pulls: 41.6M&lt;/p&gt;&lt;p&gt;Tags: 29&lt;/p&gt;</content>
  </entry>
</feed>
