<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Ollama models</title>
  <id>https://ollama.com/search?o=newest</id>
  <author>
    <name>Model Library</name>
  </author>
  <link href="https://ollama.com/search?o=newest" rel="self"/>
  <updated>2025-06-09T06:38:57.813285+00:00</updated>
  <entry>
    <title>deepseek-r1</title>
    <id>https://ollama.com/library/deepseek-r1</id>
    <link href="https://ollama.com/library/deepseek-r1"/>
    <summary>DeepSeek-R1 is a family of open reasoning models with performance approaching that of leading models, such as O3 and Gemini 2.5 Pro.</summary>
    <updated>2025-06-02T02:41:00+00:00</updated>
    <category term="1.5b"/>
    <category term="7b"/>
    <category term="8b"/>
    <category term="14b"/>
    <category term="32b"/>
    <category term="70b"/>
    <category term="671b"/>
    <category term="thinking"/>
    <content type="html">&lt;p&gt;DeepSeek-R1 is a family of open reasoning models with performance approaching that of leading models, such as O3 and Gemini 2.5 Pro.&lt;/p&gt;&lt;p&gt;Pulls: 47.5M&lt;/p&gt;&lt;p&gt;Tags: 35&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>qwen3</title>
    <id>https://ollama.com/library/qwen3</id>
    <link href="https://ollama.com/library/qwen3"/>
    <summary>Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.</summary>
    <updated>2025-05-29T01:55:00+00:00</updated>
    <category term="0.6b"/>
    <category term="1.7b"/>
    <category term="4b"/>
    <category term="8b"/>
    <category term="14b"/>
    <category term="30b"/>
    <category term="32b"/>
    <category term="235b"/>
    <category term="tools"/>
    <category term="thinking"/>
    <content type="html">&lt;p&gt;Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.&lt;/p&gt;&lt;p&gt;Pulls: 2M&lt;/p&gt;&lt;p&gt;Tags: 35&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>qwen2.5-coder</title>
    <id>https://ollama.com/library/qwen2.5-coder</id>
    <link href="https://ollama.com/library/qwen2.5-coder"/>
    <summary>The latest series of Code-Specific Qwen models, with significant improvements in code generation, code reasoning, and code fixing.</summary>
    <updated>2025-05-28T01:19:00+00:00</updated>
    <category term="0.5b"/>
    <category term="1.5b"/>
    <category term="3b"/>
    <category term="7b"/>
    <category term="14b"/>
    <category term="32b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;The latest series of Code-Specific Qwen models, with significant improvements in code generation, code reasoning, and code fixing.&lt;/p&gt;&lt;p&gt;Pulls: 5.5M&lt;/p&gt;&lt;p&gt;Tags: 199&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>llama4</title>
    <id>https://ollama.com/library/llama4</id>
    <link href="https://ollama.com/library/llama4"/>
    <summary>Meta's latest collection of multimodal models.</summary>
    <updated>2025-05-28T01:03:00+00:00</updated>
    <category term="16x17b"/>
    <category term="128x17b"/>
    <category term="vision"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;Meta's latest collection of multimodal models.&lt;/p&gt;&lt;p&gt;Pulls: 391.1K&lt;/p&gt;&lt;p&gt;Tags: 11&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>qwen2.5vl</title>
    <id>https://ollama.com/library/qwen2.5vl</id>
    <link href="https://ollama.com/library/qwen2.5vl"/>
    <summary>Flagship vision-language model of Qwen and also a significant leap from the previous Qwen2-VL.</summary>
    <updated>2025-05-22T21:01:00+00:00</updated>
    <category term="3b"/>
    <category term="7b"/>
    <category term="32b"/>
    <category term="72b"/>
    <category term="vision"/>
    <content type="html">&lt;p&gt;Flagship vision-language model of Qwen and also a significant leap from the previous Qwen2-VL.&lt;/p&gt;&lt;p&gt;Pulls: 267K&lt;/p&gt;&lt;p&gt;Tags: 17&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>llama3.2-vision</title>
    <id>https://ollama.com/library/llama3.2-vision</id>
    <link href="https://ollama.com/library/llama3.2-vision"/>
    <summary>Llama 3.2 Vision is a collection of instruction-tuned image reasoning generative models in 11B and 90B sizes.</summary>
    <updated>2025-05-22T19:15:00+00:00</updated>
    <category term="11b"/>
    <category term="90b"/>
    <category term="vision"/>
    <content type="html">&lt;p&gt;Llama 3.2 Vision is a collection of instruction-tuned image reasoning generative models in 11B and 90B sizes.&lt;/p&gt;&lt;p&gt;Pulls: 2.2M&lt;/p&gt;&lt;p&gt;Tags: 9&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>devstral</title>
    <id>https://ollama.com/library/devstral</id>
    <link href="https://ollama.com/library/devstral"/>
    <summary>Devstral: the best open source model for coding agents</summary>
    <updated>2025-05-21T14:34:00+00:00</updated>
    <category term="24b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;Devstral: the best open source model for coding agents&lt;/p&gt;&lt;p&gt;Pulls: 107.7K&lt;/p&gt;&lt;p&gt;Tags: 5&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>phi4-reasoning</title>
    <id>https://ollama.com/library/phi4-reasoning</id>
    <link href="https://ollama.com/library/phi4-reasoning"/>
    <summary>Phi 4 reasoning and reasoning plus are 14-billion parameter open-weight reasoning models that rival much larger models on complex reasoning tasks.</summary>
    <updated>2025-05-01T05:32:00+00:00</updated>
    <category term="14b"/>
    <content type="html">&lt;p&gt;Phi 4 reasoning and reasoning plus are 14-billion parameter open-weight reasoning models that rival much larger models on complex reasoning tasks.&lt;/p&gt;&lt;p&gt;Pulls: 76.1K&lt;/p&gt;&lt;p&gt;Tags: 9&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>phi4-mini-reasoning</title>
    <id>https://ollama.com/library/phi4-mini-reasoning</id>
    <link href="https://ollama.com/library/phi4-mini-reasoning"/>
    <summary>Phi 4 mini reasoning is a lightweight open model that balances efficiency with advanced reasoning ability.</summary>
    <updated>2025-05-01T03:53:00+00:00</updated>
    <category term="3.8b"/>
    <content type="html">&lt;p&gt;Phi 4 mini reasoning is a lightweight open model that balances efficiency with advanced reasoning ability.&lt;/p&gt;&lt;p&gt;Pulls: 21.5K&lt;/p&gt;&lt;p&gt;Tags: 5&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>gemma3</title>
    <id>https://ollama.com/library/gemma3</id>
    <link href="https://ollama.com/library/gemma3"/>
    <summary>The current, most capable model that runs on a single GPU.</summary>
    <updated>2025-04-18T02:08:00+00:00</updated>
    <category term="1b"/>
    <category term="4b"/>
    <category term="12b"/>
    <category term="27b"/>
    <category term="vision"/>
    <content type="html">&lt;p&gt;The current, most capable model that runs on a single GPU.&lt;/p&gt;&lt;p&gt;Pulls: 5.6M&lt;/p&gt;&lt;p&gt;Tags: 21&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>granite3.3</title>
    <id>https://ollama.com/library/granite3.3</id>
    <link href="https://ollama.com/library/granite3.3"/>
    <summary>IBM Granite 2B and 8B models are 128K context length language models that have been fine-tuned for improved reasoning and instruction-following capabilities.</summary>
    <updated>2025-04-16T14:49:00+00:00</updated>
    <category term="2b"/>
    <category term="8b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;IBM Granite 2B and 8B models are 128K context length language models that have been fine-tuned for improved reasoning and instruction-following capabilities.&lt;/p&gt;&lt;p&gt;Pulls: 100.9K&lt;/p&gt;&lt;p&gt;Tags: 3&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>deepcoder</title>
    <id>https://ollama.com/library/deepcoder</id>
    <link href="https://ollama.com/library/deepcoder"/>
    <summary>DeepCoder is a fully open-Source 14B coder model at O3-mini level, with a 1.5B version also available.</summary>
    <updated>2025-04-08T22:53:00+00:00</updated>
    <category term="1.5b"/>
    <category term="14b"/>
    <content type="html">&lt;p&gt;DeepCoder is a fully open-Source 14B coder model at O3-mini level, with a 1.5B version also available.&lt;/p&gt;&lt;p&gt;Pulls: 136.9K&lt;/p&gt;&lt;p&gt;Tags: 9&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>cogito</title>
    <id>https://ollama.com/library/cogito</id>
    <link href="https://ollama.com/library/cogito"/>
    <summary>Cogito v1 Preview is a family of hybrid reasoning models by Deep Cogito that outperform the best available open models of the same size, including counterparts from LLaMA, DeepSeek, and Qwen across most standard benchmarks.</summary>
    <updated>2025-04-08T17:38:00+00:00</updated>
    <category term="3b"/>
    <category term="8b"/>
    <category term="14b"/>
    <category term="32b"/>
    <category term="70b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;Cogito v1 Preview is a family of hybrid reasoning models by Deep Cogito that outperform the best available open models of the same size, including counterparts from LLaMA, DeepSeek, and Qwen across most standard benchmarks.&lt;/p&gt;&lt;p&gt;Pulls: 107.8K&lt;/p&gt;&lt;p&gt;Tags: 20&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>mistral-small3.1</title>
    <id>https://ollama.com/library/mistral-small3.1</id>
    <link href="https://ollama.com/library/mistral-small3.1"/>
    <summary>Building upon Mistral Small 3, Mistral Small 3.1 (2503) adds state-of-the-art vision understanding and enhances long context capabilities up to 128k tokens without compromising text performance.</summary>
    <updated>2025-04-07T16:59:00+00:00</updated>
    <category term="24b"/>
    <category term="vision"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;Building upon Mistral Small 3, Mistral Small 3.1 (2503) adds state-of-the-art vision understanding and enhances long context capabilities up to 128k tokens without compromising text performance.&lt;/p&gt;&lt;p&gt;Pulls: 127.7K&lt;/p&gt;&lt;p&gt;Tags: 5&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>openthinker</title>
    <id>https://ollama.com/library/openthinker</id>
    <link href="https://ollama.com/library/openthinker"/>
    <summary>A fully open-source family of reasoning models built using a dataset derived by distilling DeepSeek-R1.</summary>
    <updated>2025-04-04T21:52:00+00:00</updated>
    <category term="7b"/>
    <category term="32b"/>
    <content type="html">&lt;p&gt;A fully open-source family of reasoning models built using a dataset derived by distilling DeepSeek-R1.&lt;/p&gt;&lt;p&gt;Pulls: 529.4K&lt;/p&gt;&lt;p&gt;Tags: 15&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>exaone-deep</title>
    <id>https://ollama.com/library/exaone-deep</id>
    <link href="https://ollama.com/library/exaone-deep"/>
    <summary>EXAONE Deep exhibits superior capabilities in various reasoning tasks including math and coding benchmarks, ranging from 2.4B to 32B parameters developed and released by LG AI Research.</summary>
    <updated>2025-03-19T17:04:00+00:00</updated>
    <category term="2.4b"/>
    <category term="7.8b"/>
    <category term="32b"/>
    <content type="html">&lt;p&gt;EXAONE Deep exhibits superior capabilities in various reasoning tasks including math and coding benchmarks, ranging from 2.4B to 32B parameters developed and released by LG AI Research.&lt;/p&gt;&lt;p&gt;Pulls: 48.8K&lt;/p&gt;&lt;p&gt;Tags: 13&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>qwq</title>
    <id>https://ollama.com/library/qwq</id>
    <link href="https://ollama.com/library/qwq"/>
    <summary>QwQ is the reasoning model of the Qwen series.</summary>
    <updated>2025-03-13T18:55:00+00:00</updated>
    <category term="32b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;QwQ is the reasoning model of the Qwen series.&lt;/p&gt;&lt;p&gt;Pulls: 1.5M&lt;/p&gt;&lt;p&gt;Tags: 8&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>command-a</title>
    <id>https://ollama.com/library/command-a</id>
    <link href="https://ollama.com/library/command-a"/>
    <summary>111 billion parameter model optimized for demanding enterprises that require fast, secure, and high-quality AI</summary>
    <updated>2025-03-13T12:39:00+00:00</updated>
    <category term="111b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;111 billion parameter model optimized for demanding enterprises that require fast, secure, and high-quality AI&lt;/p&gt;&lt;p&gt;Pulls: 16.9K&lt;/p&gt;&lt;p&gt;Tags: 5&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>command-r7b-arabic</title>
    <id>https://ollama.com/library/command-r7b-arabic</id>
    <link href="https://ollama.com/library/command-r7b-arabic"/>
    <summary>A new state-of-the-art version of the lightweight Command R7B model that excels in advanced Arabic language capabilities for enterprises in the Middle East and Northern Africa.</summary>
    <updated>2025-02-28T21:28:00+00:00</updated>
    <category term="7b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;A new state-of-the-art version of the lightweight Command R7B model that excels in advanced Arabic language capabilities for enterprises in the Middle East and Northern Africa.&lt;/p&gt;&lt;p&gt;Pulls: 6,573&lt;/p&gt;&lt;p&gt;Tags: 5&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>phi4-mini</title>
    <id>https://ollama.com/library/phi4-mini</id>
    <link href="https://ollama.com/library/phi4-mini"/>
    <summary>Phi-4-mini brings significant enhancements in multilingual support, reasoning, and mathematics, and now, the long-awaited function calling feature is finally supported.</summary>
    <updated>2025-02-28T20:02:00+00:00</updated>
    <category term="3.8b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;Phi-4-mini brings significant enhancements in multilingual support, reasoning, and mathematics, and now, the long-awaited function calling feature is finally supported.&lt;/p&gt;&lt;p&gt;Pulls: 171.8K&lt;/p&gt;&lt;p&gt;Tags: 5&lt;/p&gt;</content>
  </entry>
</feed>
