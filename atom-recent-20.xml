<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Ollama models</title>
  <id>https://ollama.com/search?o=newest</id>
  <author>
    <name>Model Library</name>
  </author>
  <link href="https://ollama.com/search?o=newest" rel="self"/>
  <updated>2025-11-09T06:37:15.821207+00:00</updated>
  <entry>
    <title>kimi-k2-thinking</title>
    <id>https://ollama.com/library/kimi-k2-thinking</id>
    <link href="https://ollama.com/library/kimi-k2-thinking"/>
    <summary>Kimi K2 Thinking, Moonshot AI's best open-source thinking model.</summary>
    <updated>2025-11-07T01:16:00+00:00</updated>
    <content type="html">&lt;p&gt;Kimi K2 Thinking, Moonshot AI's best open-source thinking model.&lt;/p&gt;&lt;p&gt;Pulls: 2,376&lt;/p&gt;&lt;p&gt;Tags: 1&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>qwen3-vl</title>
    <id>https://ollama.com/library/qwen3-vl</id>
    <link href="https://ollama.com/library/qwen3-vl"/>
    <summary>The most powerful vision-language model in the Qwen model family to date.</summary>
    <updated>2025-10-29T23:24:00+00:00</updated>
    <category term="2b"/>
    <category term="4b"/>
    <category term="8b"/>
    <category term="30b"/>
    <category term="32b"/>
    <category term="235b"/>
    <category term="vision"/>
    <content type="html">&lt;p&gt;The most powerful vision-language model in the Qwen model family to date.&lt;/p&gt;&lt;p&gt;Pulls: 112.7K&lt;/p&gt;&lt;p&gt;Tags: 59&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>granite4</title>
    <id>https://ollama.com/library/granite4</id>
    <link href="https://ollama.com/library/granite4"/>
    <summary>Granite 4 features improved instruction following (IF) and tool-calling capabilities, making them more effective in enterprise applications.</summary>
    <updated>2025-10-29T13:53:00+00:00</updated>
    <category term="350m"/>
    <category term="1b"/>
    <category term="3b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;Granite 4 features improved instruction following (IF) and tool-calling capabilities, making them more effective in enterprise applications.&lt;/p&gt;&lt;p&gt;Pulls: 128K&lt;/p&gt;&lt;p&gt;Tags: 17&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>gpt-oss-safeguard</title>
    <id>https://ollama.com/library/gpt-oss-safeguard</id>
    <link href="https://ollama.com/library/gpt-oss-safeguard"/>
    <summary>gpt-oss-safeguard-20b and gpt-oss-safeguard-120b are safety reasoning models built-upon gpt-oss</summary>
    <updated>2025-10-29T02:04:00+00:00</updated>
    <category term="20b"/>
    <category term="120b"/>
    <category term="tools"/>
    <category term="thinking"/>
    <content type="html">&lt;p&gt;gpt-oss-safeguard-20b and gpt-oss-safeguard-120b are safety reasoning models built-upon gpt-oss&lt;/p&gt;&lt;p&gt;Pulls: 5,327&lt;/p&gt;&lt;p&gt;Tags: 3&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>minimax-m2</title>
    <id>https://ollama.com/library/minimax-m2</id>
    <link href="https://ollama.com/library/minimax-m2"/>
    <summary>MiniMax M2 is a high-efficiency large language model built for coding and agentic workflows.</summary>
    <updated>2025-10-28T18:32:00+00:00</updated>
    <content type="html">&lt;p&gt;MiniMax M2 is a high-efficiency large language model built for coding and agentic workflows.&lt;/p&gt;&lt;p&gt;Pulls: 14.4K&lt;/p&gt;&lt;p&gt;Tags: 1&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>glm-4.6</title>
    <id>https://ollama.com/library/glm-4.6</id>
    <link href="https://ollama.com/library/glm-4.6"/>
    <summary>Advanced agentic, reasoning and coding capabilities.</summary>
    <updated>2025-10-15T05:17:00+00:00</updated>
    <content type="html">&lt;p&gt;Advanced agentic, reasoning and coding capabilities.&lt;/p&gt;&lt;p&gt;Pulls: 17.4K&lt;/p&gt;&lt;p&gt;Tags: 1&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>qwen3</title>
    <id>https://ollama.com/library/qwen3</id>
    <link href="https://ollama.com/library/qwen3"/>
    <summary>Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.</summary>
    <updated>2025-10-10T20:18:00+00:00</updated>
    <category term="0.6b"/>
    <category term="1.7b"/>
    <category term="4b"/>
    <category term="8b"/>
    <category term="14b"/>
    <category term="30b"/>
    <category term="32b"/>
    <category term="235b"/>
    <category term="tools"/>
    <category term="thinking"/>
    <content type="html">&lt;p&gt;Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.&lt;/p&gt;&lt;p&gt;Pulls: 12.8M&lt;/p&gt;&lt;p&gt;Tags: 58&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>gpt-oss</title>
    <id>https://ollama.com/library/gpt-oss</id>
    <link href="https://ollama.com/library/gpt-oss"/>
    <summary>OpenAI’s open-weight models designed for powerful reasoning, agentic tasks, and versatile developer use cases.</summary>
    <updated>2025-10-09T19:47:00+00:00</updated>
    <category term="20b"/>
    <category term="120b"/>
    <category term="tools"/>
    <category term="thinking"/>
    <content type="html">&lt;p&gt;OpenAI’s open-weight models designed for powerful reasoning, agentic tasks, and versatile developer use cases.&lt;/p&gt;&lt;p&gt;Pulls: 4.1M&lt;/p&gt;&lt;p&gt;Tags: 5&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>deepseek-v3.1</title>
    <id>https://ollama.com/library/deepseek-v3.1</id>
    <link href="https://ollama.com/library/deepseek-v3.1"/>
    <summary>DeepSeek-V3.1-Terminus is a hybrid model that supports both thinking mode and non-thinking mode.</summary>
    <updated>2025-09-27T00:46:00+00:00</updated>
    <category term="671b"/>
    <category term="tools"/>
    <category term="thinking"/>
    <content type="html">&lt;p&gt;DeepSeek-V3.1-Terminus is a hybrid model that supports both thinking mode and non-thinking mode.&lt;/p&gt;&lt;p&gt;Pulls: 137.1K&lt;/p&gt;&lt;p&gt;Tags: 8&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>kimi-k2</title>
    <id>https://ollama.com/library/kimi-k2</id>
    <link href="https://ollama.com/library/kimi-k2"/>
    <summary>A state-of-the-art mixture-of-experts (MoE) language model. Kimi K2-Instruct-0905 demonstrates significant improvements in performance on public benchmarks and real-world coding agent tasks.</summary>
    <updated>2025-09-26T03:50:00+00:00</updated>
    <content type="html">&lt;p&gt;A state-of-the-art mixture-of-experts (MoE) language model. Kimi K2-Instruct-0905 demonstrates significant improvements in performance on public benchmarks and real-world coding agent tasks.&lt;/p&gt;&lt;p&gt;Pulls: 11.3K&lt;/p&gt;&lt;p&gt;Tags: 1&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>qwen3-embedding</title>
    <id>https://ollama.com/library/qwen3-embedding</id>
    <link href="https://ollama.com/library/qwen3-embedding"/>
    <summary>Building upon the foundational models of the Qwen3 series, Qwen3 Embedding provides a comprehensive range of text embeddings models in various sizes</summary>
    <updated>2025-09-23T20:26:00+00:00</updated>
    <category term="0.6b"/>
    <category term="4b"/>
    <category term="8b"/>
    <category term="embedding"/>
    <content type="html">&lt;p&gt;Building upon the foundational models of the Qwen3 series, Qwen3 Embedding provides a comprehensive range of text embeddings models in various sizes&lt;/p&gt;&lt;p&gt;Pulls: 112.3K&lt;/p&gt;&lt;p&gt;Tags: 12&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>qwen3-coder</title>
    <id>https://ollama.com/library/qwen3-coder</id>
    <link href="https://ollama.com/library/qwen3-coder"/>
    <summary>Alibaba's performant long context models for agentic and coding tasks.</summary>
    <updated>2025-09-23T19:14:00+00:00</updated>
    <category term="30b"/>
    <category term="480b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;Alibaba's performant long context models for agentic and coding tasks.&lt;/p&gt;&lt;p&gt;Pulls: 632K&lt;/p&gt;&lt;p&gt;Tags: 10&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>embeddinggemma</title>
    <id>https://ollama.com/library/embeddinggemma</id>
    <link href="https://ollama.com/library/embeddinggemma"/>
    <summary>EmbeddingGemma is a 300M parameter embedding model from Google.</summary>
    <updated>2025-09-09T00:17:00+00:00</updated>
    <category term="300m"/>
    <category term="embedding"/>
    <content type="html">&lt;p&gt;EmbeddingGemma is a 300M parameter embedding model from Google.&lt;/p&gt;&lt;p&gt;Pulls: 132.9K&lt;/p&gt;&lt;p&gt;Tags: 5&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>gemma3</title>
    <id>https://ollama.com/library/gemma3</id>
    <link href="https://ollama.com/library/gemma3"/>
    <summary>The current, most capable model that runs on a single GPU.</summary>
    <updated>2025-08-15T08:15:00+00:00</updated>
    <category term="270m"/>
    <category term="1b"/>
    <category term="4b"/>
    <category term="12b"/>
    <category term="27b"/>
    <category term="vision"/>
    <content type="html">&lt;p&gt;The current, most capable model that runs on a single GPU.&lt;/p&gt;&lt;p&gt;Pulls: 24.5M&lt;/p&gt;&lt;p&gt;Tags: 26&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>mistral-nemo</title>
    <id>https://ollama.com/library/mistral-nemo</id>
    <link href="https://ollama.com/library/mistral-nemo"/>
    <summary>A state-of-the-art 12B model with 128k context length, built by Mistral AI in collaboration with NVIDIA.</summary>
    <updated>2025-07-23T18:43:00+00:00</updated>
    <category term="12b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;A state-of-the-art 12B model with 128k context length, built by Mistral AI in collaboration with NVIDIA.&lt;/p&gt;&lt;p&gt;Pulls: 2.9M&lt;/p&gt;&lt;p&gt;Tags: 17&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>mistral</title>
    <id>https://ollama.com/library/mistral</id>
    <link href="https://ollama.com/library/mistral"/>
    <summary>The 7B model released by Mistral AI, updated to version 0.3.</summary>
    <updated>2025-07-13T00:56:00+00:00</updated>
    <category term="7b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;The 7B model released by Mistral AI, updated to version 0.3.&lt;/p&gt;&lt;p&gt;Pulls: 21.7M&lt;/p&gt;&lt;p&gt;Tags: 84&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>devstral</title>
    <id>https://ollama.com/library/devstral</id>
    <link href="https://ollama.com/library/devstral"/>
    <summary>Devstral: the best open source model for coding agents</summary>
    <updated>2025-07-04T18:29:00+00:00</updated>
    <category term="24b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;Devstral: the best open source model for coding agents&lt;/p&gt;&lt;p&gt;Pulls: 443.6K&lt;/p&gt;&lt;p&gt;Tags: 5&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>deepseek-r1</title>
    <id>https://ollama.com/library/deepseek-r1</id>
    <link href="https://ollama.com/library/deepseek-r1"/>
    <summary>DeepSeek-R1 is a family of open reasoning models with performance approaching that of leading models, such as O3 and Gemini 2.5 Pro.</summary>
    <updated>2025-07-02T06:09:00+00:00</updated>
    <category term="1.5b"/>
    <category term="7b"/>
    <category term="8b"/>
    <category term="14b"/>
    <category term="32b"/>
    <category term="70b"/>
    <category term="671b"/>
    <category term="tools"/>
    <category term="thinking"/>
    <content type="html">&lt;p&gt;DeepSeek-R1 is a family of open reasoning models with performance approaching that of leading models, such as O3 and Gemini 2.5 Pro.&lt;/p&gt;&lt;p&gt;Pulls: 69.9M&lt;/p&gt;&lt;p&gt;Tags: 35&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>gemma3n</title>
    <id>https://ollama.com/library/gemma3n</id>
    <link href="https://ollama.com/library/gemma3n"/>
    <summary>Gemma 3n models are designed for efficient execution on everyday devices such as laptops, tablets or phones.</summary>
    <updated>2025-06-27T05:02:00+00:00</updated>
    <category term="e2b"/>
    <category term="e4b"/>
    <content type="html">&lt;p&gt;Gemma 3n models are designed for efficient execution on everyday devices such as laptops, tablets or phones.&lt;/p&gt;&lt;p&gt;Pulls: 731.1K&lt;/p&gt;&lt;p&gt;Tags: 9&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>mistral-small3.2</title>
    <id>https://ollama.com/library/mistral-small3.2</id>
    <link href="https://ollama.com/library/mistral-small3.2"/>
    <summary>An update to Mistral Small that improves on function calling, instruction following, and less repetition errors.</summary>
    <updated>2025-06-20T22:59:00+00:00</updated>
    <category term="24b"/>
    <category term="vision"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;An update to Mistral Small that improves on function calling, instruction following, and less repetition errors.&lt;/p&gt;&lt;p&gt;Pulls: 739.3K&lt;/p&gt;&lt;p&gt;Tags: 5&lt;/p&gt;</content>
  </entry>
</feed>
