<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Ollama models</title>
  <id>https://ollama.com/search?o=newest</id>
  <author>
    <name>Model Library</name>
  </author>
  <link href="https://ollama.com/search?o=newest" rel="self"/>
  <updated>2025-12-13T06:39:02.555814+00:00</updated>
  <entry>
    <title>ministral-3</title>
    <id>https://ollama.com/library/ministral-3</id>
    <link href="https://ollama.com/library/ministral-3"/>
    <summary>The Ministral 3 family is designed for edge deployment, capable of running on a wide range of hardware.</summary>
    <updated>2025-12-13T01:59:00+00:00</updated>
    <category term="3b"/>
    <category term="8b"/>
    <category term="14b"/>
    <category term="vision"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;The Ministral 3 family is designed for edge deployment, capable of running on a wide range of hardware.&lt;/p&gt;&lt;p&gt;Pulls: 86.6K&lt;/p&gt;&lt;p&gt;Tags: 16&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>rnj-1</title>
    <id>https://ollama.com/library/rnj-1</id>
    <link href="https://ollama.com/library/rnj-1"/>
    <summary>Rnj-1 is a family of 8B parameter open-weight, dense models trained from scratch by Essential AI, optimized for code and STEM with capabilities on par with SOTA open-weight models.</summary>
    <updated>2025-12-12T23:44:00+00:00</updated>
    <category term="8b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;Rnj-1 is a family of 8B parameter open-weight, dense models trained from scratch by Essential AI, optimized for code and STEM with capabilities on par with SOTA open-weight models.&lt;/p&gt;&lt;p&gt;Pulls: 3,936&lt;/p&gt;&lt;p&gt;Tags: 6&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>devstral-2</title>
    <id>https://ollama.com/library/devstral-2</id>
    <link href="https://ollama.com/library/devstral-2"/>
    <summary>123B model that excels at using tools to explore codebases, editing multiple files and power software engineering agents.</summary>
    <updated>2025-12-12T01:21:00+00:00</updated>
    <category term="123b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;123B model that excels at using tools to explore codebases, editing multiple files and power software engineering agents.&lt;/p&gt;&lt;p&gt;Pulls: 1,500&lt;/p&gt;&lt;p&gt;Tags: 6&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>devstral-small-2</title>
    <id>https://ollama.com/library/devstral-small-2</id>
    <link href="https://ollama.com/library/devstral-small-2"/>
    <summary>24B model that excels at using tools to explore codebases, editing multiple files and power software engineering agents.</summary>
    <updated>2025-12-11T22:48:00+00:00</updated>
    <category term="24b"/>
    <category term="vision"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;24B model that excels at using tools to explore codebases, editing multiple files and power software engineering agents.&lt;/p&gt;&lt;p&gt;Pulls: 25.9K&lt;/p&gt;&lt;p&gt;Tags: 5&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>nomic-embed-text-v2-moe</title>
    <id>https://ollama.com/library/nomic-embed-text-v2-moe</id>
    <link href="https://ollama.com/library/nomic-embed-text-v2-moe"/>
    <summary>nomic-embed-text-v2-moe is a multilingual MoE text embedding model that excels at multilingual retrieval.</summary>
    <updated>2025-12-10T22:09:00+00:00</updated>
    <category term="embedding"/>
    <content type="html">&lt;p&gt;nomic-embed-text-v2-moe is a multilingual MoE text embedding model that excels at multilingual retrieval.&lt;/p&gt;&lt;p&gt;Pulls: 1,267&lt;/p&gt;&lt;p&gt;Tags: 1&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>deepseek-v3.2</title>
    <id>https://ollama.com/library/deepseek-v3.2</id>
    <link href="https://ollama.com/library/deepseek-v3.2"/>
    <summary>DeepSeek-V3.2, a model that harmonizes high computational efficiency with superior reasoning and agent performance.</summary>
    <updated>2025-12-09T01:54:00+00:00</updated>
    <content type="html">&lt;p&gt;DeepSeek-V3.2, a model that harmonizes high computational efficiency with superior reasoning and agent performance.&lt;/p&gt;&lt;p&gt;Pulls: 2,506&lt;/p&gt;&lt;p&gt;Tags: 1&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>qwen3-next</title>
    <id>https://ollama.com/library/qwen3-next</id>
    <link href="https://ollama.com/library/qwen3-next"/>
    <summary>The first installment in the Qwen3-Next series with strong performance in terms of both parameter efficiency and inference speed.</summary>
    <updated>2025-12-09T00:41:00+00:00</updated>
    <category term="80b"/>
    <category term="tools"/>
    <category term="thinking"/>
    <content type="html">&lt;p&gt;The first installment in the Qwen3-Next series with strong performance in terms of both parameter efficiency and inference speed.&lt;/p&gt;&lt;p&gt;Pulls: 7,633&lt;/p&gt;&lt;p&gt;Tags: 10&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>gemma3</title>
    <id>https://ollama.com/library/gemma3</id>
    <link href="https://ollama.com/library/gemma3"/>
    <summary>The current, most capable model that runs on a single GPU.</summary>
    <updated>2025-12-05T21:46:00+00:00</updated>
    <category term="270m"/>
    <category term="1b"/>
    <category term="4b"/>
    <category term="12b"/>
    <category term="27b"/>
    <category term="vision"/>
    <content type="html">&lt;p&gt;The current, most capable model that runs on a single GPU.&lt;/p&gt;&lt;p&gt;Pulls: 28M&lt;/p&gt;&lt;p&gt;Tags: 29&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>mistral-large-3</title>
    <id>https://ollama.com/library/mistral-large-3</id>
    <link href="https://ollama.com/library/mistral-large-3"/>
    <summary>A general-purpose multimodal mixture-of-experts model for production-grade tasks and enterprise workloads.</summary>
    <updated>2025-12-02T23:19:00+00:00</updated>
    <content type="html">&lt;p&gt;A general-purpose multimodal mixture-of-experts model for production-grade tasks and enterprise workloads.&lt;/p&gt;&lt;p&gt;Pulls: 4,204&lt;/p&gt;&lt;p&gt;Tags: 1&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>cogito-2.1</title>
    <id>https://ollama.com/library/cogito-2.1</id>
    <link href="https://ollama.com/library/cogito-2.1"/>
    <summary>The Cogito v2.1 LLMs are instruction tuned generative models. All models are released under MIT license for commercial use.</summary>
    <updated>2025-11-21T20:18:00+00:00</updated>
    <category term="671b"/>
    <content type="html">&lt;p&gt;The Cogito v2.1 LLMs are instruction tuned generative models. All models are released under MIT license for commercial use.&lt;/p&gt;&lt;p&gt;Pulls: 14.6K&lt;/p&gt;&lt;p&gt;Tags: 6&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>deepseek-ocr</title>
    <id>https://ollama.com/library/deepseek-ocr</id>
    <link href="https://ollama.com/library/deepseek-ocr"/>
    <summary>DeepSeek-OCR is a vision-language model that can perform token-efficient OCR.</summary>
    <updated>2025-11-19T20:26:00+00:00</updated>
    <category term="3b"/>
    <category term="vision"/>
    <content type="html">&lt;p&gt;DeepSeek-OCR is a vision-language model that can perform token-efficient OCR.&lt;/p&gt;&lt;p&gt;Pulls: 56.1K&lt;/p&gt;&lt;p&gt;Tags: 3&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>gemini-3-pro-preview</title>
    <id>https://ollama.com/library/gemini-3-pro-preview</id>
    <link href="https://ollama.com/library/gemini-3-pro-preview"/>
    <summary>Google's most intelligent model with SOTA reasoning and multimodal understanding, and powerful agentic and vibe coding capabilities.</summary>
    <updated>2025-11-18T17:06:00+00:00</updated>
    <content type="html">&lt;p&gt;Google's most intelligent model with SOTA reasoning and multimodal understanding, and powerful agentic and vibe coding capabilities.&lt;/p&gt;&lt;p&gt;Pulls: 32.3K&lt;/p&gt;&lt;p&gt;Tags: 1&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>kimi-k2-thinking</title>
    <id>https://ollama.com/library/kimi-k2-thinking</id>
    <link href="https://ollama.com/library/kimi-k2-thinking"/>
    <summary>Kimi K2 Thinking, Moonshot AI's best open-source thinking model.</summary>
    <updated>2025-11-07T01:16:00+00:00</updated>
    <content type="html">&lt;p&gt;Kimi K2 Thinking, Moonshot AI's best open-source thinking model.&lt;/p&gt;&lt;p&gt;Pulls: 13.4K&lt;/p&gt;&lt;p&gt;Tags: 1&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>qwen3-vl</title>
    <id>https://ollama.com/library/qwen3-vl</id>
    <link href="https://ollama.com/library/qwen3-vl"/>
    <summary>The most powerful vision-language model in the Qwen model family to date.</summary>
    <updated>2025-10-29T23:24:00+00:00</updated>
    <category term="2b"/>
    <category term="4b"/>
    <category term="8b"/>
    <category term="30b"/>
    <category term="32b"/>
    <category term="235b"/>
    <category term="vision"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;The most powerful vision-language model in the Qwen model family to date.&lt;/p&gt;&lt;p&gt;Pulls: 717.3K&lt;/p&gt;&lt;p&gt;Tags: 59&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>granite4</title>
    <id>https://ollama.com/library/granite4</id>
    <link href="https://ollama.com/library/granite4"/>
    <summary>Granite 4 features improved instruction following (IF) and tool-calling capabilities, making them more effective in enterprise applications.</summary>
    <updated>2025-10-29T13:53:00+00:00</updated>
    <category term="350m"/>
    <category term="1b"/>
    <category term="3b"/>
    <category term="tools"/>
    <content type="html">&lt;p&gt;Granite 4 features improved instruction following (IF) and tool-calling capabilities, making them more effective in enterprise applications.&lt;/p&gt;&lt;p&gt;Pulls: 283K&lt;/p&gt;&lt;p&gt;Tags: 17&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>gpt-oss-safeguard</title>
    <id>https://ollama.com/library/gpt-oss-safeguard</id>
    <link href="https://ollama.com/library/gpt-oss-safeguard"/>
    <summary>gpt-oss-safeguard-20b and gpt-oss-safeguard-120b are safety reasoning models built-upon gpt-oss</summary>
    <updated>2025-10-29T02:04:00+00:00</updated>
    <category term="20b"/>
    <category term="120b"/>
    <category term="tools"/>
    <category term="thinking"/>
    <content type="html">&lt;p&gt;gpt-oss-safeguard-20b and gpt-oss-safeguard-120b are safety reasoning models built-upon gpt-oss&lt;/p&gt;&lt;p&gt;Pulls: 28.1K&lt;/p&gt;&lt;p&gt;Tags: 3&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>minimax-m2</title>
    <id>https://ollama.com/library/minimax-m2</id>
    <link href="https://ollama.com/library/minimax-m2"/>
    <summary>MiniMax M2 is a high-efficiency large language model built for coding and agentic workflows.</summary>
    <updated>2025-10-28T18:32:00+00:00</updated>
    <content type="html">&lt;p&gt;MiniMax M2 is a high-efficiency large language model built for coding and agentic workflows.&lt;/p&gt;&lt;p&gt;Pulls: 26.7K&lt;/p&gt;&lt;p&gt;Tags: 1&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>glm-4.6</title>
    <id>https://ollama.com/library/glm-4.6</id>
    <link href="https://ollama.com/library/glm-4.6"/>
    <summary>Advanced agentic, reasoning and coding capabilities.</summary>
    <updated>2025-10-15T05:17:00+00:00</updated>
    <content type="html">&lt;p&gt;Advanced agentic, reasoning and coding capabilities.&lt;/p&gt;&lt;p&gt;Pulls: 31.8K&lt;/p&gt;&lt;p&gt;Tags: 1&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>qwen3</title>
    <id>https://ollama.com/library/qwen3</id>
    <link href="https://ollama.com/library/qwen3"/>
    <summary>Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.</summary>
    <updated>2025-10-10T20:18:00+00:00</updated>
    <category term="0.6b"/>
    <category term="1.7b"/>
    <category term="4b"/>
    <category term="8b"/>
    <category term="14b"/>
    <category term="30b"/>
    <category term="32b"/>
    <category term="235b"/>
    <category term="tools"/>
    <category term="thinking"/>
    <content type="html">&lt;p&gt;Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.&lt;/p&gt;&lt;p&gt;Pulls: 14.9M&lt;/p&gt;&lt;p&gt;Tags: 58&lt;/p&gt;</content>
  </entry>
  <entry>
    <title>gpt-oss</title>
    <id>https://ollama.com/library/gpt-oss</id>
    <link href="https://ollama.com/library/gpt-oss"/>
    <summary>OpenAI’s open-weight models designed for powerful reasoning, agentic tasks, and versatile developer use cases.</summary>
    <updated>2025-10-09T19:47:00+00:00</updated>
    <category term="20b"/>
    <category term="120b"/>
    <category term="tools"/>
    <category term="thinking"/>
    <content type="html">&lt;p&gt;OpenAI’s open-weight models designed for powerful reasoning, agentic tasks, and versatile developer use cases.&lt;/p&gt;&lt;p&gt;Pulls: 5.1M&lt;/p&gt;&lt;p&gt;Tags: 5&lt;/p&gt;</content>
  </entry>
</feed>
